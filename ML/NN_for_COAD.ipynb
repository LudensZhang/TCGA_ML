{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c6b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c393fd",
   "metadata": {},
   "source": [
    "查看设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ebc986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(f'The model will be running on {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2be43",
   "metadata": {},
   "source": [
    "定义一个NN类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ed72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, feature_count, class_count):\n",
    "        super (Net, self).__init__()\n",
    "        \n",
    "        self.hidden_layers = nn.Sequential(nn.Linear(feature_count, 1000),\n",
    "                                            nn.ReLU(True),\n",
    "                                            nn.Linear(1000, 5000),\n",
    "                                            nn.ReLU(True),\n",
    "                                            nn.Linear(5000, 5000),\n",
    "                                            nn.ReLU(True),\n",
    "                                            nn.Linear(5000, 5000),\n",
    "                                            nn.ReLU(True),\n",
    "                                            nn.Linear(5000, 1000),\n",
    "                                            nn.ReLU(True),\n",
    "                                            nn.Linear(1000, class_count))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = self.hidden_layers(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec97042",
   "metadata": {},
   "source": [
    "定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d385b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(whole_train_set, model_name):\n",
    "    train_set, valid_set = random_split(whole_train_set, [int(0.8*len(whole_train_set)),\n",
    "                                                            len(whole_train_set) - int(0.8*len(whole_train_set))])\n",
    "    train_loader = DataLoader(train_set, batch_size = int(0.2*len(train_set)), shuffle = True)\n",
    "    valid_loader = DataLoader(valid_set, batch_size = int(0.5*len(valid_set)), shuffle = True)\n",
    "    \n",
    "    model = Net(500, 2)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        running_train_loss = 0.0  \n",
    "        running_val_loss = 0.0\n",
    "        correct, total = 0, 0 \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            X = data[0].to(device)\n",
    "            y = data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(X)  \n",
    "            loss = criterion(outputs, y.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss\n",
    "        \n",
    "        train_loss = running_train_loss/len(train_loader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            for i, data in enumerate(valid_loader, 0):\n",
    "                X = data[0].to(device)\n",
    "                y = data[1].to(device)\n",
    "            \n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y.long())\n",
    "                _, y_pred = torch.max(outputs, dim = 1)\n",
    "                running_val_loss += loss\n",
    "                total += outputs.size(0)\n",
    "                correct += (y == y_pred).sum().item()\n",
    "            \n",
    "        val_loss = running_val_loss/len(valid_loader)\n",
    "        \n",
    "        accuracy = 100*correct/total\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            torch.save(model.state_dict(), f'./best_model/{model_name}_best.pth')\n",
    "            print('The model has been saved for the best accuracy %d %%'%(accuracy))\n",
    "            best_accuracy = accuracy\n",
    "        \n",
    "        if epoch == 0:\n",
    "            print('The model is working fine!')\n",
    "\n",
    "        if (epoch + 1)%100 == 0:\n",
    "            print('Completed training epoch', epoch + 1, 'Training Loss is: %.4f' %train_loss, 'Validation Loss is: %.4f' %val_loss, 'Accuracy is %d %%' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eede4f8",
   "metadata": {},
   "source": [
    "定义测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d12efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(whole_test_set, model_name):\n",
    "    model = Net(500, 2)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(f'./best_model/{model_name}_best.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    X = whole_test_set.dataset[:][0].to(device)\n",
    "    y = whole_test_set.dataset[:][1].to(device)\n",
    "    \n",
    "    y_pred = model(X)\n",
    "    print(\"AUC:{:.4f} on test data.\".format(roc_auc_score(y.cpu().detach().numpy(), \n",
    "                                                            y_pred.cpu().detach().numpy()[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfebb7",
   "metadata": {},
   "source": [
    "导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0e58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../COAD/metadata.csv', index_col = 2)['pathologic_stage_label']\n",
    "trans_data  = pd.read_csv('./selected_transcriptome.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef307c6d",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a341314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StageNormalize(stage):\n",
    "    stage = str(stage)\n",
    "    if re.search('Stage IV', stage):\n",
    "        return 3\n",
    "    elif re.search('Stage III', stage):\n",
    "        return 2\n",
    "    elif re.search('Stage II', stage):\n",
    "        return 1\n",
    "    elif re.search('Stage I', stage):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "metadata = metadata.apply(StageNormalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0272e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcriptom_id\n",
       "TCGA-AA-3841-01A    1.0\n",
       "TCGA-D5-6924-01A    1.0\n",
       "TCGA-AA-3861-01A    1.0\n",
       "TCGA-AA-3510-01A    1.0\n",
       "TCGA-AA-A024-01A    1.0\n",
       "Name: pathologic_stage_label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd28375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.dropna(inplace = True)\n",
    "metadata.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda0c8d",
   "metadata": {},
   "source": [
    "Stage I vs Stage II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "849ae1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved for the best accuracy 72 %\n",
      "The model is working fine!\n",
      "The model has been saved for the best accuracy 76 %\n",
      "Completed training epoch 100 Training Loss is: 0.0277 Validation Loss is: 0.4988 Accuracy is 72 %\n",
      "Completed training epoch 200 Training Loss is: 0.0006 Validation Loss is: 0.8040 Accuracy is 65 %\n",
      "AUC:0.8082 on test data.\n"
     ]
    }
   ],
   "source": [
    "processed_X  = trans_data.loc[metadata[(metadata == 0) | (metadata == 1)].index]\n",
    "labels = metadata[(metadata == 0) | (metadata == 1)].apply(lambda x: 1 if x != 0 else 0)\n",
    "processed_X = np.array(processed_X).astype(np.float32)\n",
    "labels = np.array(labels)\n",
    "\n",
    "processed_data = TensorDataset(torch.from_numpy(processed_X), torch.from_numpy(labels))\n",
    "whole_train_set, whole_test_set = random_split(processed_data, [int(0.8*len(processed_data)),\n",
    "                                                                    len(processed_data) - int(0.8*len(processed_data))])\n",
    "\n",
    "train(whole_train_set, 'stage_1_vs_stage_2')\n",
    "test(whole_test_set, 'stage_1_vs_stage_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f34029",
   "metadata": {},
   "source": [
    "Stage I vs Stage III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849ae1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved for the best accuracy 29 %\n",
      "The model is working fine!\n",
      "The model has been saved for the best accuracy 70 %\n",
      "The model has been saved for the best accuracy 73 %\n",
      "The model has been saved for the best accuracy 75 %\n",
      "Completed training epoch 100 Training Loss is: 0.0861 Validation Loss is: 1.8167 Accuracy is 75 %\n",
      "The model has been saved for the best accuracy 78 %\n",
      "Completed training epoch 200 Training Loss is: 0.0018 Validation Loss is: 1.8367 Accuracy is 73 %\n",
      "AUC:0.8987 on test data.\n"
     ]
    }
   ],
   "source": [
    "processed_X  = trans_data.loc[metadata[(metadata == 0) | (metadata == 2)].index]\n",
    "labels = metadata[(metadata == 0) | (metadata == 2)].apply(lambda x: 1 if x != 0 else 0)\n",
    "processed_X = np.array(processed_X).astype(np.float32)\n",
    "labels = np.array(labels)\n",
    "\n",
    "processed_data = TensorDataset(torch.from_numpy(processed_X), torch.from_numpy(labels))\n",
    "whole_train_set, whole_test_set = random_split(processed_data, [int(0.8*len(processed_data)),\n",
    "                                                                    len(processed_data) - int(0.8*len(processed_data))])\n",
    "\n",
    "train(whole_train_set, 'stage_1_vs_stage_3')\n",
    "test(whole_test_set, 'stage_1_vs_stage_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda0c8d",
   "metadata": {},
   "source": [
    "Stage I vs Stage IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "849ae1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved for the best accuracy 59 %\n",
      "The model is working fine!\n",
      "The model has been saved for the best accuracy 81 %\n",
      "Completed training epoch 100 Training Loss is: 0.0215 Validation Loss is: 0.5630 Accuracy is 77 %\n",
      "Completed training epoch 200 Training Loss is: 0.0004 Validation Loss is: 0.7789 Accuracy is 74 %\n",
      "AUC:0.7677 on test data.\n"
     ]
    }
   ],
   "source": [
    "processed_X  = trans_data.loc[metadata[(metadata == 0) | (metadata == 3)].index]\n",
    "labels = metadata[(metadata == 0) | (metadata == 3)].apply(lambda x: 1 if x != 0 else 0)\n",
    "processed_X = np.array(processed_X).astype(np.float32)\n",
    "labels = np.array(labels)\n",
    "\n",
    "processed_data = TensorDataset(torch.from_numpy(processed_X), torch.from_numpy(labels))\n",
    "whole_train_set, whole_test_set = random_split(processed_data, [int(0.8*len(processed_data)),\n",
    "                                                                    len(processed_data) - int(0.8*len(processed_data))])\n",
    "\n",
    "train(whole_train_set, 'stage_1_vs_stage_4')\n",
    "test(whole_test_set, 'stage_1_vs_stage_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda0c8d",
   "metadata": {},
   "source": [
    "Stage II vs Stage III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "849ae1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved for the best accuracy 63 %\n",
      "The model is working fine!\n",
      "The model has been saved for the best accuracy 68 %\n",
      "The model has been saved for the best accuracy 74 %\n",
      "The model has been saved for the best accuracy 75 %\n",
      "Completed training epoch 100 Training Loss is: 0.1123 Validation Loss is: 1.0499 Accuracy is 58 %\n",
      "Completed training epoch 200 Training Loss is: 0.0016 Validation Loss is: 2.0027 Accuracy is 62 %\n",
      "AUC:0.7893 on test data.\n"
     ]
    }
   ],
   "source": [
    "processed_X  = trans_data.loc[metadata[(metadata == 1) | (metadata == 2)].index]\n",
    "labels = metadata[(metadata == 1) | (metadata == 2)].apply(lambda x: 1 if x != 1 else 0)\n",
    "processed_X = np.array(processed_X).astype(np.float32)\n",
    "labels = np.array(labels)\n",
    "\n",
    "processed_data = TensorDataset(torch.from_numpy(processed_X), torch.from_numpy(labels))\n",
    "whole_train_set, whole_test_set = random_split(processed_data, [int(0.8*len(processed_data)),\n",
    "                                                                    len(processed_data) - int(0.8*len(processed_data))])\n",
    "\n",
    "train(whole_train_set, 'stage_2_vs_stage_3')\n",
    "test(whole_test_set, 'stage_2_vs_stage_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda0c8d",
   "metadata": {},
   "source": [
    "Stage II vs Stage IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849ae1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved for the best accuracy 75 %\n",
      "The model is working fine!\n",
      "The model has been saved for the best accuracy 79 %\n",
      "Completed training epoch 100 Training Loss is: 0.0194 Validation Loss is: 1.0740 Accuracy is 68 %\n",
      "Completed training epoch 200 Training Loss is: 0.0006 Validation Loss is: 1.5907 Accuracy is 68 %\n",
      "AUC:0.7229 on test data.\n"
     ]
    }
   ],
   "source": [
    "processed_X  = trans_data.loc[metadata[(metadata == 1) | (metadata == 3)].index]\n",
    "labels = metadata[(metadata == 1) | (metadata == 3)].apply(lambda x: 1 if x != 1 else 0)\n",
    "processed_X = np.array(processed_X).astype(np.float32)\n",
    "labels = np.array(labels)\n",
    "\n",
    "processed_data = TensorDataset(torch.from_numpy(processed_X), torch.from_numpy(labels))\n",
    "whole_train_set, whole_test_set = random_split(processed_data, [int(0.8*len(processed_data)),\n",
    "                                                                    len(processed_data) - int(0.8*len(processed_data))])\n",
    "\n",
    "train(whole_train_set, 'stage_2_vs_stage_4')\n",
    "test(whole_test_set, 'stage_2_vs_stage_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda0c8d",
   "metadata": {},
   "source": [
    "Stage III vs Stage IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d311c858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved for the best accuracy 68 %\n",
      "The model is working fine!\n",
      "Completed training epoch 100 Training Loss is: 0.0044 Validation Loss is: 1.4286 Accuracy is 57 %\n",
      "Completed training epoch 200 Training Loss is: 0.0002 Validation Loss is: 1.8590 Accuracy is 60 %\n",
      "AUC:0.5963 on test data.\n"
     ]
    }
   ],
   "source": [
    "processed_X  = trans_data.loc[metadata[(metadata == 2) | (metadata == 3)].index]\n",
    "labels = metadata[(metadata == 2) | (metadata == 3)].apply(lambda x: 1 if x != 2 else 0)\n",
    "processed_X = np.array(processed_X).astype(np.float32)\n",
    "labels = np.array(labels)\n",
    "\n",
    "processed_data = TensorDataset(torch.from_numpy(processed_X), torch.from_numpy(labels))\n",
    "whole_train_set, whole_test_set = random_split(processed_data, [int(0.8*len(processed_data)),\n",
    "                                                                    len(processed_data) - int(0.8*len(processed_data))])\n",
    "\n",
    "train(whole_train_set, 'stage_3_vs_stage_4')\n",
    "test(whole_test_set, 'stage_3_vs_stage_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa94a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cba455981152ac3392ff4135c02b5b977f84f41280d0b3586aaa56380a6cadc9"
  },
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
